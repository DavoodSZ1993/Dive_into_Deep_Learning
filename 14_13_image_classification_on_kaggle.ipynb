{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtalpKmDz/ITzFd/PYJ0IO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavoodSZ1993/Dive_into_Deep_Learning/blob/main/14_13_image_classification_on_kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF69eLmqCkXY",
        "outputId": "f90f1b74-ed28-4985-8b8d-d06e8df26d47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install d2l==1.0.0-alpha1.post0 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14.13 Image Classification (CIFAR-10) on Kaggle"
      ],
      "metadata": {
        "id": "swZ5GUGtCsxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import math\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "mEmFeTCPCsdu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 14.13.1 Obtaining and Organizing the Dataset"
      ],
      "metadata": {
        "id": "diydoiT_Dvog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Downloading the Dataset"
      ],
      "metadata": {
        "id": "8R6l8tn6IJR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d2l.DATA_HUB['cifar10_tiny'] = (d2l.DATA_URL + 'kaggle_cifar10_tiny.zip',\n",
        "                                '2068874e4b9a9f0fb07ebe0ad2b29754449ccacd')\n",
        "demo = True\n",
        "\n",
        "if demo:\n",
        "  data_dir = d2l.download_extract('cifar10_tiny')\n",
        "else:\n",
        "  data_dir = '../data/cifar-10/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c953zL-oD0hI",
        "outputId": "cc372468-1350-46d7-921d-f6737faf28f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ../data/kaggle_cifar10_tiny.zip from http://d2l-data.s3-accelerate.amazonaws.com/kaggle_cifar10_tiny.zip...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Organizing the Dataset"
      ],
      "metadata": {
        "id": "N3Tdy7aVJNH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_csv_labels(fname):\n",
        "  \"\"\"Read 'fname' to return a filename to label dictionary.\"\"\"\n",
        "  with open(fname, 'r') as f:\n",
        "    # Skip the file header line (column name)\n",
        "    lines = f.readlines()[1:]\n",
        "  tokens = [l.rstrip().split(',') for l in lines]\n",
        "  return dict(((name, label) for name, label in tokens))\n",
        "\n",
        "labels = read_csv_labels(os.path.join(data_dir, 'trainLabels.csv'))\n",
        "print('# training examples: ', len(labels))\n",
        "print('# classes: ', len(set(labels.values())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG-jx6wYJQB8",
        "outputId": "7d3c0780-7146-4861-a46b-b3bf124d66c4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# training examples:  1000\n",
            "# classes:  10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def copyfile(filename, target_dir):\n",
        "  \"\"\"Copy a file into a target directory.\"\"\"\n",
        "  os.makedirs(target_dir, exist_ok=True)\n",
        "  shutil.copy(filename, target_dir)\n",
        "\n",
        "def reorg_train_valid(data_dir, labels, valid_ratio):\n",
        "  \"\"\"Split the validation set out of the original training set.\"\"\"\n",
        "  # The number of examples of the class that has the fewest examples in the training dataset.\n",
        "  n = collections.Counter(labels.values()).most_common()[-1][1]\n",
        "  # The number of examples per class for the validation set\n",
        "  n_valid_per_label = max(1, math.floor(n * valid_ratio))\n",
        "  label_count = {}\n",
        "  for train_file in os.listdir(os.path.join(data_dir, 'train')):\n",
        "    label = labels[train_file.split('.')[0]]\n",
        "    fname = os.path.join(data_dir, 'train', train_file)\n",
        "    copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n",
        "                                 'train_valid', label))\n",
        "    if label not in label_count or label_count[label] < n_valid_per_label:\n",
        "      copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n",
        "                                   'valid', label))\n",
        "      label_count[label] = label_count.get(label, 0) + 1\n",
        "    else:\n",
        "      copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n",
        "                                   'train', label))\n",
        "  return n_valid_per_label"
      ],
      "metadata": {
        "id": "j_8Ozsy2PjZs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reorg_test(data_dir):\n",
        "  \"\"\"Organize the testing set for data loading during prediction.\"\"\"\n",
        "  for test_file in os.listdir(os.path.join(data_dir, 'test')):\n",
        "    copyfile(os.path.join(data_dir, 'test', test_file),\n",
        "             os.path.join(data_dir, 'train_valid_test', 'test',\n",
        "                          'unknown'))"
      ],
      "metadata": {
        "id": "HGUmrZyxmTyu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reorg_cifar10_data(data_dir, valid_ratio):\n",
        "  labels = read_csv_labels(os.path.join(data_dir, 'trainLabels.csv'))\n",
        "  reorg_train_valid(data_dir, labels, valid_ratio)\n",
        "  reorg_test(data_dir)"
      ],
      "metadata": {
        "id": "a7w17Z3enE9T"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32 if demo else 128\n",
        "valid_ratio = 0.1\n",
        "reorg_cifar10_data(data_dir, valid_ratio)"
      ],
      "metadata": {
        "id": "6SgQvcTfnv7u"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 14.13.2 Image Augmentation"
      ],
      "metadata": {
        "id": "q8k53kLsoU7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize(40),\n",
        "    torchvision.transforms.RandomResizedCrop(32, scale=(0.64, 1.0),\n",
        "                                             ratio=(1.0, 1.0)),\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
        "                                     [0.2023, 0.1994, 0.2010])])"
      ],
      "metadata": {
        "id": "hMjh6FT9oY7V"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_test = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
        "                                     [0.2023, 0.1194, 0.2010])])"
      ],
      "metadata": {
        "id": "AYwWDcR8pYEW"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}