{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzwc07oxNnDA9w5GpGBcDK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavoodSZ1993/Dive_into_Deep_Learning/blob/main/15_4_pretraining_word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDetmrxC4HVR",
        "outputId": "22663b03-5ac0-421d-dff4-09d08db2311d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install d2l==1.0.0-alpha1.post0 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 15.4 Pretraining word2vec"
      ],
      "metadata": {
        "id": "iWU6m-5a4Re2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "JOJ1zeMh4VDM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size, max_window_size, num_noise_words = 512, 5, 5\n",
        "data_iter, vocab = d2l.load_data_ptb(batch_size, max_window_size,\n",
        "                                     num_noise_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qByzRJ3E43fU",
        "outputId": "5cea1eb1-b005-4846-de6c-838de372da67"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ../data/ptb.zip from http://d2l-data.s3-accelerate.amazonaws.com/ptb.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 15.4.1 The Skip-Gram Model"
      ],
      "metadata": {
        "id": "N0da67yyqhmo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Embedding Layer"
      ],
      "metadata": {
        "id": "c2TkLDsGql10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed = nn.Embedding(num_embeddings=20, embedding_dim=4)\n",
        "print(f'Parameter embedding_weight ({embed.weight.shape}, '\n",
        "      f'dtype={embed.weight.dtype})')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvsaRa_ZqpFC",
        "outputId": "48aefd0d-b16a-41f3-bb23-3a20b37fc99d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter embedding_weight (torch.Size([20, 4]), dtype=torch.float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6]])\n",
        "embed(x), embed(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMUtsGxirs6M",
        "outputId": "2bb03c17-d5ce-413a-9bf5-75f9b8684241"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-0.1920,  0.2009,  0.9424, -0.7605],\n",
              "          [ 0.5801, -2.1541, -0.3997,  0.6834],\n",
              "          [ 1.0473, -0.3226,  0.9451, -0.4419]],\n",
              " \n",
              "         [[-1.0552,  0.9272, -0.1512,  1.2081],\n",
              "          [-0.8601,  0.7703, -1.5981,  0.8459],\n",
              "          [-0.1257, -1.7021, -1.3471,  0.0515]]], grad_fn=<EmbeddingBackward0>),\n",
              " torch.Size([2, 3, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining the Forward Propagation"
      ],
      "metadata": {
        "id": "Z3j7ZT-4r-zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def skip_gram(center, contexts_and_negatives, embed_v, embed_u):\n",
        "  v = embed_v(center)\n",
        "  u = embed_u(contexts_and_negatives)\n",
        "  pred = torch.bmm(v, u.permute(0, 2, 1))\n",
        "  return pred"
      ],
      "metadata": {
        "id": "ffXIGCbNsCx7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skip_gram(torch.ones((2, 1), dtype=torch.long),\n",
        "          torch.ones((2, 4), dtype=torch.long), embed, embed).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upk0t-gnsp9U",
        "outputId": "f269a2db-0f26-4a4a-f654-9f7971fbe392"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 15.4.2 Training"
      ],
      "metadata": {
        "id": "9q8pt7PXs6rC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Binary Cross-Entropy Loss"
      ],
      "metadata": {
        "id": "PDfLsHa_tNBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SigmoidBCELoss(nn.Module):\n",
        "  # Binary cross-entropy loss with masking\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, inputs, target, mask=None):\n",
        "    out = nn.functional.binary_cross_entropy_with_logits(\n",
        "        inputs, target, weight=mask, reduction=\"none\")\n",
        "    return out.mean(dim=1)\n",
        "\n",
        "loss = SigmoidBCELoss()"
      ],
      "metadata": {
        "id": "6UUq6yoys9cb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = torch.tensor([[1.1, -2.2, 3.3, -4.4]] * 2)\n",
        "label = torch.tensor([[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]])\n",
        "mask = torch.tensor([[1, 1, 1, 1], [1, 1, 0, 0]])\n",
        "loss(pred, label, mask) * mask.shape[1] / mask.sum(axis=1)"
      ],
      "metadata": {
        "id": "ECODoSTtubPU",
        "outputId": "96bc9365-3437-4e47-f541-eea47592389b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9352, 1.8462])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmd(x):\n",
        "  return -math.log(1 / (1 + math.exp(-x)))\n",
        "\n",
        "print(f'{(sigmd(1.1) + sigmd(2.2) + sigmd(-3.3) + sigmd(4.4)) / 4: .4f}')\n",
        "print(f'{(sigmd(-1.1) + sigmd(-2.2)) / 2:.4f}')"
      ],
      "metadata": {
        "id": "SkF_WdIfvFjr",
        "outputId": "9d9b71ee-5021-44c0-eee0-b3589b5ba394",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0.9352\n",
            "1.8462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initializing Model Parameters"
      ],
      "metadata": {
        "id": "PoWr_boQvtZd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nqiFBJL9vxCH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}