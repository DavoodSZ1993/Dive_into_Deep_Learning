{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5UFX53Ihj9m8Aq4VIpmzK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavoodSZ1993/Dive_into_Deep_Learning/blob/main/15_4_pretraining_word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDetmrxC4HVR",
        "outputId": "22663b03-5ac0-421d-dff4-09d08db2311d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install d2l==1.0.0-alpha1.post0 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 15.4 Pretraining word2vec"
      ],
      "metadata": {
        "id": "iWU6m-5a4Re2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "JOJ1zeMh4VDM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size, max_window_size, num_noise_words = 512, 5, 5\n",
        "data_iter, vocab = d2l.load_data_ptb(batch_size, max_window_size,\n",
        "                                     num_noise_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qByzRJ3E43fU",
        "outputId": "5cea1eb1-b005-4846-de6c-838de372da67"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ../data/ptb.zip from http://d2l-data.s3-accelerate.amazonaws.com/ptb.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 15.4.1 The Skip-Gram Model"
      ],
      "metadata": {
        "id": "N0da67yyqhmo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Embedding Layer"
      ],
      "metadata": {
        "id": "c2TkLDsGql10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed = nn.Embedding(num_embeddings=20, embedding_dim=4)\n",
        "print(f'Parameter embedding_weight ({embed.weight.shape}, '\n",
        "      f'dtype={embed.weight.dtype})')"
      ],
      "metadata": {
        "id": "BvsaRa_ZqpFC",
        "outputId": "48aefd0d-b16a-41f3-bb23-3a20b37fc99d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter embedding_weight (torch.Size([20, 4]), dtype=torch.float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6]])\n",
        "embed(x), embed(x).shape"
      ],
      "metadata": {
        "id": "JMUtsGxirs6M",
        "outputId": "2bb03c17-d5ce-413a-9bf5-75f9b8684241",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-0.1920,  0.2009,  0.9424, -0.7605],\n",
              "          [ 0.5801, -2.1541, -0.3997,  0.6834],\n",
              "          [ 1.0473, -0.3226,  0.9451, -0.4419]],\n",
              " \n",
              "         [[-1.0552,  0.9272, -0.1512,  1.2081],\n",
              "          [-0.8601,  0.7703, -1.5981,  0.8459],\n",
              "          [-0.1257, -1.7021, -1.3471,  0.0515]]], grad_fn=<EmbeddingBackward0>),\n",
              " torch.Size([2, 3, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining the Forward Propagation"
      ],
      "metadata": {
        "id": "Z3j7ZT-4r-zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def skip_gram(center, contexts_and_negatives, embed_v, embed_u):\n",
        "  v = embed_v(center)\n",
        "  u = embed_u(contexts_and_negatives)\n",
        "  pred = torch.bmm(v, u.permute(0, 2, 1))\n",
        "  return pred"
      ],
      "metadata": {
        "id": "ffXIGCbNsCx7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skip_gram(torch.ones((2, 1), dtype=torch.long),\n",
        "          torch.ones((2, 4), dtype=torch.long), embed, embed).shape"
      ],
      "metadata": {
        "id": "upk0t-gnsp9U",
        "outputId": "f269a2db-0f26-4a4a-f654-9f7971fbe392",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 15.4.2 Training"
      ],
      "metadata": {
        "id": "9q8pt7PXs6rC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6UUq6yoys9cb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}