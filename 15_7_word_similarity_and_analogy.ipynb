{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAmdFcH3hMZR5IjavHnQT/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavoodSZ1993/Dive_into_Deep_Learning/blob/main/15_7_word_similarity_and_analogy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqPDFiWsHvIC",
        "outputId": "1ae0ba3b-cc63-4f6a-d73a-7e7fcfeb2c38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install d2l==1.0.0-alpha1.post0 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 15.7 Word Similarity and Analogy"
      ],
      "metadata": {
        "id": "yaXTwpKMH_32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "9HoE-X8QIOs4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 15.7.1 Loading Pretrained Word Vectors"
      ],
      "metadata": {
        "id": "9SjMvBPfIVOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d2l.DATA_HUB['glove.6b.50d'] = (d2l.DATA_URL + 'glove.6B.50d.zip',\n",
        "                                '0b8703943ccdb6eb788e6f091b8946e82231bc4d')\n",
        "\n",
        "d2l.DATA_HUB['glove.6b.100d'] = (d2l.DATA_URL + 'glove.6B.100d.zip',\n",
        "                                 'cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a')\n",
        "\n",
        "d2l.DATA_HUB['glove.42b.300d'] = (d2l.DATA_URL + 'glove.42B.300d.zip',\n",
        "                                  'b5116e234e9eb9076672cfeabf5469f3eec904fa')\n",
        "\n",
        "d2l.DATA_HUB['wiki.en'] = (d2l.DATA_URL + 'wiki.en.zip',\n",
        "                           'c1816da3821ae9f43899be655002f6c723e91b88')\n"
      ],
      "metadata": {
        "id": "--F5433FIcAk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenEmbedding:\n",
        "  \"\"\"Token Embedding.\"\"\"\n",
        "  def __init__(self, embedding_name):\n",
        "    self.idx_to_token, self.idx_to_vec = self._load_embedding(\n",
        "        embedding_name)\n",
        "    self.unknown_idx = 0\n",
        "    self.token_to_idx = {token: idx for idx, token in\n",
        "                         enumerate(self.idx_to_token)}\n",
        "\n",
        "  def _load_embedding(self, embedding_name):\n",
        "    idx_to_token, idx_to_vec = ['<unk>'], []\n",
        "    data_dir = d2l.download_extract(embedding_name)\n",
        "    with open(os.path.join(data_dir, 'vec.txt'), 'r') as f:\n",
        "      for line in f:\n",
        "        elems = line.rstrip().split(' ')\n",
        "        token, elems = elems[0], [float(elem) for elem in elems[1:]]\n",
        "        if len(elems) > 1:\n",
        "          idx_to_token.append(token)\n",
        "          idx_to_vec.append(elems)\n",
        "    idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\n",
        "    return idx_to_token, torch.tensor(idx_to_vec)\n",
        "\n",
        "  def __getitem__(self, tokens):\n",
        "    indices = [self.token_to_idx.get(token, self.unknown_idx)\n",
        "              for token in tokens]\n",
        "    vecs = self.idx_to_vec[torch.tensor(indices)]\n",
        "    return vecs\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.idx_to_token)\n"
      ],
      "metadata": {
        "id": "GQ02CYUcJ1-g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_6b50d = TokenEmbedding('glove.6b.50d')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS_YQrt_NdtG",
        "outputId": "ad01787a-68b2-4dd6-85f6-57cac4b53903"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ../data/glove.6B.50d.zip from http://d2l-data.s3-accelerate.amazonaws.com/glove.6B.50d.zip...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(glove_6b50d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30xSmxATNzAt",
        "outputId": "dab2c573-ad02-44dd-88b2-3d35a3113ded"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400001"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_6b50d.token_to_idx['beautiful'], glove_6b50d.idx_to_token[3367]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QMgYt2oN2tG",
        "outputId": "86f82b95-f04a-4efe-d6bc-016b3f510b81"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3367, 'beautiful')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 15.7.2 Applying Pretrained Word Vectors"
      ],
      "metadata": {
        "id": "4Ruuutg_PJaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Word Similarity"
      ],
      "metadata": {
        "id": "qlCvIWYoPP35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knn(W, x, k):\n",
        "  # Add 1e-9 for numerical stability\n",
        "  cos = torch.mv(W, x.reshape(-1,)) / (\n",
        "      torch.sqrt(torch.sum(W * W, axis=1) + 1e-9) *\n",
        "      torch.sqrt((x * x).sum()))\n",
        "  _, topk = torch.topk(cos, k=k)\n",
        "  return topk, [cos[int(i)] for i in topk]"
      ],
      "metadata": {
        "id": "xdvhG1qPPbT9"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}